<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Kubernetes on Learning Loop</title><link>https://harshrai654.github.io/blogs/tags/kubernetes/</link><description>Recent content in Kubernetes on Learning Loop</description><generator>Hugo -- 0.155.1</generator><language>en-us</language><lastBuildDate>Fri, 30 Jan 2026 23:43:37 +0530</lastBuildDate><atom:link href="https://harshrai654.github.io/blogs/tags/kubernetes/index.xml" rel="self" type="application/rss+xml"/><item><title>Debugging HTTP 503 UC Errors in Istio Service Mesh</title><link>https://harshrai654.github.io/blogs/debugging-http-503-uc-errors-in-istio-service-mesh/</link><pubDate>Fri, 30 Jan 2026 23:43:37 +0530</pubDate><guid>https://harshrai654.github.io/blogs/debugging-http-503-uc-errors-in-istio-service-mesh/</guid><description>&lt;h2 id="background"&gt;Background&lt;/h2&gt;
&lt;p&gt;To obtain more relevant metrics and a comprehensive understanding of traces when external API requests access our systems, We opted to enable tracing for the network mesh components situated above the Kubernetes service. This specifically covers the entire request flow from its initiation: the ingress gateway receives the request and routes it according to defined rules to a particular K8s service; then, the Istio sidecar proxy containers, running alongside our application containers in the same pod, receive and proxy the request to main containers, where our Node.js server process ultimately handle it and generate the appropriate response.
Before enabling tracing for istio mesh, tracing for a HTTP request began when the request reached our application container at the pod level, with HTTP auto-instrumentation serving as the trace root.&lt;/p&gt;</description></item></channel></rss>